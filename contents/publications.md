<div class="project-list">

<div class="project-card">
    <div class="project-content">
        <h3>Deployment of a Real-time 6D Pose Estimation System for On-Site Smart Operator Based on a MR Headset</h3>
        <p><strong>Tech Stack:</strong> Python, PyTorch, OpenCV, C++, Docker, Bash scripting</p>
        <p><strong>Developed in collaboration with Thales Alenia Space.</strong></p>
        <p>üìå The core aim of this project is to create a system usable on a Mixed Reality device for Smart Operators, assisting in the production process. By deploying PoET, a state-of-the-art 6D pose estimation model, the system provides real-time object recognition and spatial tracking to minimize errors and optimize workflows in manufacturing and assembly environments.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/MMST-Multi-Modal_Sign_Language_Translator">MMST: Multimodal Sign Language Translator</a></h3>
        <p><strong>Tech Stack:</strong> Python, OpenAI API, React, Node.js</p>
        <p>üìå MMST is a web application that enables translation between speech, text, and sign language (SL) across multiple languages. Utilizing OpenAI models, it processes input in real time, providing accurate and efficient translations in the desired modality. Designed for deaf and hard-of-hearing individuals, interpreters, educators, and learners, MMST enhances accessibility and communication through advanced multimodal AI-driven translation.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/Biometric-Systems-Project">Gait Recognition with Wii Balance Board</a></h3>
        <p><strong>Tech Stack:</strong> Python, BrainBLOX</p>
        <p>üìå This project explores the potential of affordable hardware for biometric recognition by developing a gait identification system using the Nintendo Wii Balance Board. By capturing balance and pressure data while a person walks, the system analyzes unique walking patterns. Initially started as a research initiative, it demonstrates how everyday devices can be leveraged for advanced security and accessibility applications.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/NLP_Videogame-Playability-Analysis">NLP Video Game Playability Analysis Based on Players‚Äô Reviews</a></h3>
        <p><strong>Tech Stack:</strong> PySpark, NLTK, Pandas, Matplotlib</p>
        <p>üìå This project is inspired by the research paper: 
            <em>A Data-Driven Approach for Video Game Playability Analysis Based on Players‚Äô Reviews</em>.  
            [<a href="https://dl.acm.org/doi/10.1145/3487922.3493793" target="_blank">Read the paper</a>]. It focuses on assessing video game playability through a data-driven methodology that leverages player reviews on Steam as the primary source of analysis. Using NLP and big data analysis techniques, it evaluates functionality, usability, and gameplay to provide an objective analysis of game quality and user experience, structured according to the Paavilainen framework, while developing custom metrics to score games to generate graphical representations of the results. </p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3>
            <a href="https://github.com/iladesio/DroNETworkSimulator">
                DroNETworkSimulator - Autonomous Networking
            </a>
        </h3>
        <p><strong>Tech Stack:</strong> Python, TensorFlow, Matplotlib</p>
        <p>üìå This project is an optimized version of DroNET, a Python-based simulator designed for experimenting with routing algorithms and mobility models in unmanned aerial vehicle (UAV) networks.</p>
        <p>The project is divided into two parts:
            <ul>
                <li><strong>Homework 1:</strong> Addressing a drone routing problem using Reinforcement Learning techniques.</li>
                <li>
                    <strong>Homework 2:</strong> Implementation based on the paper:  
                    <em>Jianmin LIU, Qi WANG, Chentao HE, and Yongjun XU. Ardeep: Adaptive and Reliable 
                    Routing Protocol for Mobile Robotic Networks with Deep Reinforcement Learning.</em>  
                    [<a href="https://ieeexplore.ieee.org/document/9314848" target="_blank">Read the paper</a>]
                </li>
            </ul>
        </p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3>Karate VR - Meta Quest 3</h3>
        <p><strong>Tech Stack:</strong> Python, Meta SDK, Unity, C#</p>
        <p>üìå Karate VR aims to revolutionize karate training through a Virtual Reality platform. This game allows users to practice kumite defensive techniques and blocks with real-time feedback on their movements.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/PuzzleBlock-BlockchainProject-Server">PuzzleBlock</a></h3>
        <p><strong>Tech Stack:</strong> Python, Unity, Solidity, C#, JavaScript</p>
        <p>üìå PuzzleBlock is a decentralized game application (DApp) designed to showcase the fundamental aspects and potential of blockchain technology through engaging gameplay in Unity, based on Ethereum. Players progress through various levels with the opportunity to purchase Non-Fungible Tokens (NFTs), blending education with competition.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/SoundFlowProject/report/blob/main/Project_Cloud_Computing_Report.pdf">SoundFlow - AWS Cloud Computing Project</a></h3>
        <p><strong>Tech Stack:</strong> Python, AWS, Spotify API, React </p>
        <p>üìå SoundFlow is a cloud-powered music recommendation system that analyzes a text insert by the user to detect emotions and suggest the perfect Spotify track. By combining AWS services for auto-scaling and efficient machine learning model integration, it assigns an emotion score to the text and matches it with a relevant song, delivering a personalized and dynamic listening experience. </p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/NA-sound-4Everybody">Immersed in the Sound of Space - NASA Space App Challenge 2023 üèÜ</a></h3>
        <p><strong>Tech Stack:</strong> Python, OpenCV, React, Color Thief</p>
        <p>üìå Immersed in the Sound of Space is an audiovisual project that uses computer vision and generative sound design to transform Hubble Space Telescope footage into an immersive sonic experience. By analyzing the dominant colors in each frame, the system generates a synchronized soundscape, dynamically linking visual data to audio. This fusion creates an accessible way to experience space through sound.</p>
    </div>
</div>

</div>
