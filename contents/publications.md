<div class="project-list">

<div class="project-card">
    <div class="project-content">
        <h3>Deployment of a Real-time 6D Pose Estimation system for on-site smart operator based on a MR Headset</a></h3>
        <p><strong>Tech Stack:</strong> Python, PyTorch, OpenCV, C++, Docker, Bash scripting </p>
        <strong>Developed in collaboration with Thales Alenia Space.</strong></p>
        <p>üìå The core aim of this project system is to create an entirely system usable on a Mixed Reality device used by Smart Operators , as a tool of providing assistance in carrying out or facilitating
completion of the various steps in the production process, by deploying PoET, a state-of-the-art 6D pose estimation model, the system provides real-time object recognition and spatial tracking real-time to minimizes errors, and optimizes workflows in manufacturing and assembly environments.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3>Karate VR - Meta Quest 3</a></h3>
        <p><strong>Tech Stack:<strong> Python, Meta SDK, Unity, C#</p>
        <p>üìå Karate VR aims to revolutionize karate training through a Virtual Reality platform. This game allows users to practice kumite defensive techniques and blocks with real-time feedbacks of their movements.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/MMST-Multi-Modal_Sign_Language_Translator">MMST: Multimodal Sign Language Translator </a></h3>
        <p><strong>Tech Stack:</strong> Python, OpenAI API, React, Node.js</p>
        <p>üìå MMST is a web application that enables translation between speech, text, and sign language (SL) across multiple languages. Utilizing deep learning models, it processes input in real time, providing accurate and efficient translations in the desired modality. Designed for deaf and hard-of-hearing individuals, interpreters, educators, and learners, MMST enhances accessibility and communication through advanced multimodal AI-driven translation.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/PuzzleBlock-BlockchainProject-Server">PuzzleBlock</a></h3>
        <p><strong>Tech Stack:<strong> Python, Unity, Solidity, C#, JavaScript</p>
        <p>üìå PuzzleBlock is 
a decentralized game application (DApp) designed to show the fundamental aspects
and potential of blockchain technology through engaging gameplay in Unity, based
on Ethereum. In this journey, users will progress through various levels, with
the opportunity of purchasing Non-Fungible Tokens (NFTs). Players from around
the world can compete, enhancing the learning experience through the integration of
competitive spirit with educational value.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/Biometric-Systems-Project">Gait Recognition with Wii Balance Board </a></h3>
        <p><strong>Tech Stack:</strong> Python, BrainBLOX </p>
        <p>üìå This project explores the potential of affordable hardware for biometric recognition by developing a gait identification system using the Nintendo Wii Balance Board. By capturing balance and pressure data while a person walks, the system analyzes unique walking patterns. Initially started as a research initiative, it demonstrates how everyday devices can be leveraged for advanced security and accessibility applications.</p>
    </div>
</div>

<div class="project-card">
    <div class="project-content">
        <h3><a href="https://github.com/iladesio/NA-sound-4Everybody">Immersed in the sound of space - NASA space app challenge 2023 üèÜ</a></h3>
        <p><strong>Tech Stack:</strong>Python, OpenCV, React, Color Thief</p>
        <p>üìå Immersed in the Sound of Space is an audiovisual project that uses computer vision and generative sound design to transform Hubble Space Telescope footage into an immersive sonic experience. By analyzing the dominant colors in each frame, the system generates a synchronized soundscape, dynamically linking visual data to audio. This fusion of these elements allowing people to enjoy and creating an immersive way to experience space through sound.</p>
    </div>
</div>

</div>
